<div align="center">

# ğŸŒŸ **OmniPerception** 
*Omnidirectional Collision Avoidance for Legged Locomotion in Dynamic Environments*
 ###  CoRL 2025  

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![CUDA](https://img.shields.io/badge/CUDA-11.0%2B-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Beta-orange.svg)]()

**Accelerated sensor simulation with GPU-optimized lidar sensors for large-scale robotics environments**

[ğŸš€ Quick Start](#-getting-started) â€¢ [ğŸ“š Documentation](#-integration-guide) â€¢ [ğŸ¯ Examples](#-quick-usage) â€¢ [ğŸ› Issues](https://github.com/aCodeDog/OmniPerception/issues)

</div>

---

## ğŸ“– **Table of Contents**

- [ğŸŒŸ Project Overview](#-project-status)
- [âš¡ Performance](#-performance-highlights)  
- [ğŸ”§ Supported Hardware](#-supported-hardware)
- [ğŸ¨ Visualization](#-visualization-examples)
- [ğŸš€ Getting Started](#-getting-started)
- [ğŸ“š Integration Guide](#-integration-guide)
- [ğŸ¤ Contributing](#-acknowledge)

---

## ğŸ“‹ **Project Status**

| Component | Status | Description |
|-----------|---------|-------------|
| ğŸ¯ **LidarSensor** | ğŸš§ **Released[Half]** | High-performance GPU-accelerated lidar simulation |
| ğŸ¤– **Training Code** | ğŸš§ **In Progress** | Reinforcement learning integration |
| ğŸš€ **Deploy Code** | ğŸ“… **Planned** | Production deployment utilities |

## âš¡ **Performance Highlights**

- **ğŸ”¥ Ultra-Fast Rendering**: 250ms per step for 4,096 environments with 20,000 rays each (RTX 4090)
- **ğŸ¯ Multi-Sensor Support**: 11+ lidar sensor types including Livox and Velodyne series
- **ğŸŒ Multi-Platform**: Supports IsaacGym, Genesis, Mujoco, and Isaac Sim
- **âš¡ GPU Acceleration**: CUDA-optimized ray tracing with Warp backend

## âœ¨ **Key Features**

<div align="center">

| ğŸ¯ **Precision** | âš¡ **Performance** | ğŸ”§ **Flexibility** | ğŸŒ **Integration** |
|:---:|:---:|:---:|:---:|
| Realistic sensor modeling | GPU-accelerated computation | 11+ sensor types | multi-simulation platforms |
| Self-occlusion support | 250ms/4K environments | Custom configurations | Easy API integration |
| Noise simulation | CUDA optimization | Pattern-based scanning | Multi-robot support |

</div>

## ğŸ”§ **Supported Hardware**

### **Lidar Sensors**
<table>
<tr>
<td>

**Livox Series**
- Mid-360 ğŸŸ¢
- Avia ğŸŸ¢  
- Horizon ğŸŸ¢
- HAP ğŸŸ¢
- Mid-40/70 ğŸŸ¢
- Tele ğŸŸ¢

</td>
<td>

**Traditional Spinning**
- Velodyne HDL-64 ğŸŸ¢
- Velodyne VLP-32 ğŸŸ¢
- Ouster OS-128 ğŸŸ¢
- Custom Grid Patterns ğŸŸ¢

</td>
</tr>
</table>

### **Simulation Platforms**
- **IsaacGym** - NVIDIA's physics simulation platform
- **Genesis** - High-performance physics engine  
- **IsaacLab** - Next-generation robotics simulation platform
- **Mujoco** - Advanced physics simulation
- **Isaac Sim** - Omniverse-based robotics simulation

## ğŸ¨ **Visualization Examples**

### **Real-time Lidar Simulation**

<div align="center">

**Livox Mid-360 on Unitree G1 Robot**
![Mid360](https://github.com/aCodeDog/OmniPerception/blob/main/resources/images/Mid360_g1.gif)

**Environment Scanning with Obstacle Detection**
![Mid360](https://github.com/aCodeDog/OmniPerception/blob/main/resources/images/mid360_no_shelf.gif)

*Features: Self-occlusion modeling, real-time point cloud generation, multi-environment support*

</div>

---

## ğŸ’¡ **Development Status**

> **ğŸ“¢ Important Note**: This project is under active development. While the LidarSensor module is fully functional and optimized, we're continuously improving documentation and code structure. For any issues or questions, please [open an issue](https://github.com/aCodeDog/OmniPerception/issues).

---

# ğŸš€ **Getting Started**

## ğŸ“¦ **Installation**

### **Prerequisites**
- Python 3.8+
- CUDA 11.0+ (for GPU acceleration)
- One of: IsaacGym, Genesis, Mujoco, or Isaac Sim (<= 4.5). Note: Isaac Sim 5.0 don't spported.

### **Quick Install**
```bash
# Install core dependencies
pip install warp-lang[extras] taichi

# Install LidarSensor
cd LidarSensor
pip install -e .
```

### **Optional Dependencies**
```bash
# For ROS integration (optional)
source /opt/ros/humble/setup.bash

# For advanced visualization (optional)  
pip install matplotlib open3d
```

## ğŸ¯ **Quick Usage**

### **1. Basic Example - IsaacGym**
```bash
# Generate self-occlusion mesh (first time only)
cd LidarSensor/resources/robots/g1_29/
python process_body_mesh.py

# Run example with Unitree G1
cd LidarSensor/example/isaacgym
python unitree_g1.py
```

### **2. ROS Integration Example**
```bash
# Start ROS visualization
source /opt/ros/humble/setup.bash
/usr/bin/python3 LidarSensor/LidarSensor/sensor_pattern/sensor_lidar/lidar_vis_ros2.py
```

### **3. Custom Configuration**
```python
from LidarSensor.sensor_config.lidar_sensor_config import LidarConfig, LidarType

# Create custom sensor configuration
config = LidarConfig(
    sensor_type=LidarType.MID360,
    max_range=30.0,
    enable_sensor_noise=False
)
```






## **ğŸš€ Platform-Specific Integration Guides**

Choose your simulation platform for detailed installation and usage instructions:

### **ğŸ“¦ IsaacLab** - *Recommended for large-scale RL training*
> **Native LiDAR integration with 7+ Livox sensor types and optimized performance**

**Key Features**: 
- âœ… Native `LidarSensor` class integration  
- âœ… Realistic Livox patterns (`.npy` files)
- âœ… Optimized for 1000+ environments  
- âœ… Easy dataclass configuration

**ğŸ“‚ [**Complete IsaacLab Guide**](https://github.com/aCodeDog/OmniPerception/blob/main/LidarSensor/LidarSensor/example/isaaclab/)**

---

### **ğŸ® IsaacGym** - *For NVIDIA GPU-accelerated physics*  
> **Direct GPU ray-casting with Warp integration**

**Key Features**:
- âœ… GPU-accelerated ray tracing
- âœ… Multiple sensor configurations  
- âœ… Real-time visualization
- âœ… Flexible terrain integration

**ğŸ“‚ [**Complete IsaacGym Guide**](https://github.com/aCodeDog/OmniPerception/blob/main/LidarSensor/LidarSensor/example/isaacgym/)**

---

### **ğŸŒŸ Genesis** - *For high-performance physics simulation*
> **Modern physics engine with optimized LiDAR support**

**Key Features**:
- âœ… High-performance physics
- âœ… Multiple robot platforms
- âœ… Realistic sensor modeling
- âœ… Cross-platform support

**ğŸ“‚ [**Complete Genesis Guide**](https://github.com/aCodeDog/OmniPerception/blob/main/LidarSensor/LidarSensor/example/genesis/)**



## **ğŸ¤ Contributing & Support**

- **ğŸ› Issues**: Report bugs or request features via GitHub Issues
- **ğŸ“– Documentation**: Platform-specific guides in `/example/` directories  
- **ğŸ”¬ Research**: Cite our work if you use OmniPerception in research
- **ğŸ’¬ Discussions**: Join our community for tips and collaboration





### **Cite**

```
@article{wang2025omni,
  title={Omni-Perception: Omnidirectional Collision Avoidance for Legged Locomotion in Dynamic Environments},
  author={Wang, Zifan and Ma, Teli and Jia, Yufei and Yang, Xun and Zhou, Jiaming and Ouyang, Wenlong and Zhang, Qiang and Liang, Junwei},
  journal={arXiv preprint arXiv:2505.19214},
  year={2025}
}
```

### **Acknowledgments**